{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Data Science and Machine Learning Capstone Project - Ammarsha\n\nIn this project I will analyze the 311 complaints related to Housing and Building in NYC.\n\nFirst, let's ingest the dataset."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_94a05f71faed4d5b84a2c32aeed24a76 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='WixE9p6t4-6ZxAdl72POcvmGPCNXXRdz73w6L_XhkxCS',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_94a05f71faed4d5b84a2c32aeed24a76.get_object(Bucket='pythonammarsha-donotdelete-pr-rz2i5aqel02zrh',Key='311_Service_Requests_from_2010_to_Present_min.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 1: The dataset contains complaints logged since what date?\n\nWe can sort dataframe by created date to find out the first data logged in:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.sort_values(by='Created Date')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 2: The dataset contains complaints logged till what date?\n\nUsing the head method:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 3: How many incidents have a missing Incident Address?\n\nUsing the isna() function to find the values of NaN in a column:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df[\"Incident Address\"].isna().sum()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "For Question 4 and 5, let's retreive the Bronx and Queens data from PLUTO dataset."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "body = client_94a05f71faed4d5b84a2c32aeed24a76.get_object(Bucket='pythonammarsha-donotdelete-pr-rz2i5aqel02zrh',Key='BX_18v1.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\nbx = pd.read_csv(body)\nbx.head()\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "body = client_94a05f71faed4d5b84a2c32aeed24a76.get_object(Bucket='pythonammarsha-donotdelete-pr-rz2i5aqel02zrh',Key='QN_18v1.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\nqn = pd.read_csv(body)\nqn.head()\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 4: How many valid ZIP Codes exist in the Bronx PLUTO dataset?\n\nUsing the value_counts function we can quickly determine the number of ZIP codes in the Bronx"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "bx['ZipCode'].value_counts().count()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 5: How many valid ZIP Codes exist in the Queens PLUTO dataset?\n\nUsing the same value_counts method from Question 4 we can determine unique ZIP Codes for Queens:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "qn['ZipCode'].value_counts().count()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Section 2 - What is the Top Complaint Type\n\nIn this section we'd like to figure what kind of complaint the HPD should focus on."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 1: What is the total number of complaints that exist in the dataset?\n\nUsing the count function:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.count",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 2: How many different Complaint Types can you find in the dataset, including duplicates entries of the same type?\n\nUsing the value counts we can determine how many unique complaints in the dataset"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df['Complaint Type'].value_counts().count()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 3: How many Elevator complaints can you find in the dataset?\n\nQuestion 4: How many Electric complaints can you find in the dataset?\n\nQuestion 5: Using 80,000 as a threshold, what complaint type(s) do you recommend the Department of Housing Preservation and Development of New York City address first? Select all that apply.\n\nAgain, use the value_counts function to count the complaints. This function will help us figuring out the answer for each question."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df['Complaint Type'].value_counts()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Elevator complaints: 6,725 complaints\n\nElectric complaints: 307,311 complaints\n\nComplaints over 80,000: Heating and both of Heat/Hot Water\n\nLet's make a graph out of it:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import matplotlib.pyplot as plt\ndf['Complaint Type'].value_counts().plot(kind='bar', figsize=(10, 6))\n\nplt.xlabel('Complaint Type')\nplt.ylabel('Numbers of Occurence')\nplt.title('Complaint occurence based on their type')\n\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Section 3 - What Areas Should the Agency Focus On?\n\nWe will use the dataset to determine whether HPD should focus on a certain borough, ZIP code, or street."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 1: For the complaint types that you selected in the previous module that had at least 80,000 complaints logged, which borough had the highest number of complaints submitted?\n\nQuestion 2: For the complaint types that you selected in the previous module that had a total number that exceeded 80,000 complaints, which borough had the lowest number of complaints submitted?\n\nLet's make a new dataframe where we group both \"Heating\" and \"Heat/Hot Water\" as both complaints are over 80,000."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ht = df[['Complaint Type', 'Closed Date', 'Borough', 'Street Name', 'Incident Zip']]\nht.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ht1 = ht.loc[df['Complaint Type'].isin(['HEAT/HOT WATER', 'HEATING'])]\nht1.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's find the Borough with most complaints using the value_counts function:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ht1['Borough'].value_counts()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ht1['Borough'].value_counts().plot(kind='barh', figsize=(10, 6))\n\nplt.xlabel('Borough')\nplt.ylabel('Numbers of Occurence')\nplt.title('Heating and Hot Water Complaints in Five Borough of NYC')\n\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 3: For the complaint types that you selected in the previous module that had at least 80,000 complaints logged, which ZIP code had the highest number of complainted submitted?\n\nLet's again use the value_counts function to determine which ZIP code has the highest number of complaints."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ht1['Incident Zip'].value_counts().head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ht1['Incident Zip'].value_counts().head().plot(kind='barh', figsize=(10, 6))\n\nplt.xlabel('Zip Code')\nplt.ylabel('Numbers of Occurence')\nplt.title('Top 5 Area based on ZIP code withHeating and Hot Water Complaints in NYC')\n\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 4: For the complaint types that you selected in the previous module that had at least 80,000 complaints logged, the address 89-21 Elmhurst Avenue had the highest number of complainted submitted?\n\nAgain, value_counts."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ht1['Street Name'].value_counts().head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 5: For the complaint types that you selected in the previous module that had at least 80,000 complaints logged, how many of the submitted tickets were closed?\n\nLet's count the non null values from the Closed Date column."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ht1['Closed Date'].count()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Section 4 - What Is the Relationship between Housing Characteristics and Complaints?\n\nIn this section we will determine whether the problem identified (Heating and Hot Water Complaints) have an obvious relationship with any particular characteristic of the houses."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Question 1: Can you determine the age of the building from the PLUTO dataset?\n    \nLet's look at the BX dataset as The Bronx is the borough with most complaints."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "bx.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This is too much for us to handle, obviously. Let's reduce the column numbers so it's bearable to analyze."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "bx1 = bx[['Address', 'BldgArea', 'BldgDepth', 'BuiltFAR', 'CommFAR', 'FacilFAR', 'Lot', 'LotArea', 'LotDepth', 'NumBldgs', 'NumFloors', 'OfficeArea', 'ResArea', 'ResidFAR', 'RetailArea', 'YearBuilt', 'YearAlter1', 'ZipCode', 'YCoord', 'XCoord']]\nbx1.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "So the answer is YES, because we have the YearBuilt column that determines the year a building was built.\n\nTo answer if there are correlations between the aspects of buildings and complaints, let's make a new dataset from the 311 data where all the borough is Bronx."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "bx_df = df[df['Borough'] == 'BRONX']\nbx_df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "bx_df = bx_df.loc[df['Complaint Type'].isin(['HEAT/HOT WATER', 'HEATING'])]\nbx_df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now that we have two modified database (bx_df & bx), let's merge it. First we drop null values on bx_df's incident adress:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "bx_df.dropna(subset = [\"Incident Address\"], axis = 0, inplace=True)\nbx_df[\"Incident Address\"].isnull().sum()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "All sorted out. Now let's focus on the address with the most complaints by (again) using value_counts function:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "bx_df['Incident Address'].value_counts()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's make a cleaned, well-formatted dataframe to group the complaints by address."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "grp = bx_df[['Incident Address', 'Complaint Type']].groupby(['Incident Address'])\nct_bx = grp.count()\nct_bx.columns = ['Complaint Amount']\nct_bx.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "From now further on we'll use ct_bx and bx dataframe. Let's drop duplicates from bx dataframe first.\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "bx1.drop_duplicates(subset=\"Address\", keep=False, inplace=True)\nbx1.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "bx1['Address'].value_counts().head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "LET'S MERGE THE DATA!!!"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "fin_df = pd.merge(ct_bx, bx1, left_index=True, right_on=\"Address\", how=\"right\")\nfin_df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "fin_df.info()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "fin_df[\"HOT/HEAT WATER\"] = fin_df[\"Complaint Amount\"]\nfin_df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we replace null values with 0.0 in the HEAT/HOT WATER column using nan numpy functions"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import numpy as np\nfin_df['HOT/HEAT WATER'].replace(np.nan, 0.0, inplace = True)\nfin_df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We change the 0.0 values in HOT/HEAT WATER column with T/F statements to indicate whether there's a complaint or not in that particular address. Then we change the NaN values in Complaint Amount with 0.0."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "fin_df['HOT/HEAT WATER'] = np.where(fin_df['HOT/HEAT WATER'] >  0, True, False)\nfin_df['Complaint Amount'].replace(np.nan, 0.0, inplace = True)\nfin_df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we identify columns where the YearBuilt data is 0:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "fin_df.loc[fin_df['YearBuilt'] == 0]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Replacing NaN values in coordinates with 00.0000"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import datetime as dt\ntoday=dt.datetime.now().date()\nfin_df['YCoord'] = fin_df.YCoord.fillna('00.000').astype(float)\nfin_df['XCoord'] = fin_df.XCoord.fillna('00.000').astype(float) \nfin_df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "One last check of null values in the dataframe..."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "fin_df.isnull().sum()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "fin_df['ZipCode'] = fin_df.ZipCode.fillna('00.000').astype(float)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "fin_df.isnull().sum()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we are cleared from null values. Let's make a new dataframe regarding with the building's age."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_age = fin_df[[\"Complaint Amount\", \"YearBuilt\"]]\ndf_age = df_age[df_age.YearBuilt != 0]\ndf_age[\"Age\"] = 2020 - df_age[\"YearBuilt\"]\ndf_age.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's use Pearson Correlation to determine whether age have correlations with the amount of complaint."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import scipy.stats as stats\nstats.pearsonr(df_age[\"Complaint Amount\"],df_age[\"Age\"])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We can see that there's a small correlation (0.039) between the amount of complaints and building's age. Since the P value is less than 0.001 we can be confident about it. But how about all the correlations? Let's map it so we can learn about it better:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import seaborn as sns\nplt.figure(figsize=(20,12))\ncor = fin_df.corr(method='pearson')\nsns.heatmap(cor, annot = True, cmap=plt.cm.Reds)\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Hmm, it's still a bit too much and as we can see the correlation between complaint amounts and other aspects of the field are still small. Let's simplify the study by making a new dataframe with selected columns."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "new_df = fin_df[[\"Complaint Amount\",\"YearBuilt\",\"BldgArea\",\"BldgDepth\",\"NumBldgs\",\"NumFloors\",\"OfficeArea\"]]\n#dropping 0 year built data\nnew_df = new_df[new_df.YearBuilt != 0]\nnew_df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#adding age column to the new_df\nnew_df[\"Age\"] = 2020 - new_df[\"YearBuilt\"]\nnew_df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#checking null values\nnew_df.isnull().sum()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "plt.figure(figsize=(14,10))\ncor1 = new_df.corr(method='pearson')\nsns.heatmap(cor1, annot = True, cmap=plt.cm.Reds)\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "So, we can conclude that the aspect of building with the strongest correlation with the number of complaints is NumFloors (Number of Floors). We'll use this model to analyze the case deeper."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Section 5 - Can a predictive model be built for future prediction of the possibility of complaints identified?\n\nWe'll predict the number of future complaints by building a predictive model based on the dataframe we have right now. Let's use the linear regression concept to predict the complaints over time. First, we select the appropriate data in a new, simplify, set of dataframe."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dfp = df[['Borough', 'Closed Date', 'Complaint Type', 'Created Date', 'Incident Address', 'Incident Zip', 'Latitude', 'Longitude', 'Street Name', 'Status']]\ndfp.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Select only HEAT/HOT WATER & HEATING in the BRONX borough:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dfp = dfp.loc[dfp['Complaint Type'].isin(['HEAT/HOT WATER', 'HEATING'])]\ndfp.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dfp = dfp.loc[dfp['Borough'].isin(['BRONX'])]\ndfp.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "To see the yearly changes in our over 80000 complaint, let's set the created date into datetime first:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dfp['Created Date'] = pd.to_datetime(dfp['Created Date'])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dfp['Created Date'].head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Use the datetime library to group the dataframe into yearly case:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import datetime as dt\ndfg = dfp.groupby(dfp['Created Date'].dt.year)\ndfg = dfg.count()\ndfg",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's plot the yearly complaint:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dfg['Complaint Type'].plot(kind = 'line')\n\nplt.xlabel('Year')\nplt.ylabel('Number of Complaints')\nplt.title('Yearly Complaints of Heating Issue in the Bronx')\n\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's eliminate the data from 2010 and 2020 since it's incomplete and might be irrelevant for our prediction. Then we define the X and y for our prediction."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#defining X\nX = dfg.index[1:-1]\nX = [X.tolist()]\nX = np.asarray(X)\nX = X.reshape(-1, 1)\nX",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#defining y\ny = dfg['Complaint Type'][1:-1]\ny",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Into the prediction..."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.linear_model import LinearRegression \nfrom sklearn.preprocessing import PolynomialFeatures \n\nlr = LinearRegression()\n\npol = PolynomialFeatures(degree = 4) \nX_pol = pol.fit_transform(X) \n \nlr.fit(X_pol, y)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's visualize the polynomial regression to see if it's close enough with the result..."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "plt.scatter(X, y, color = 'green') \nplt.plot(X, lr.predict(X_pol), color = 'blue') \n \nplt.xlabel('Years') \nplt.ylabel('Number of Complaints')\nplt.title('Predicted vs Actual number of complaints')\n  \nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Close enough. Now let's predict the number of complaints..."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "lr.predict(pol.fit_transform([[2020]]))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Conclusion\n\n1. The top complaint that 311 receives throughout the decade is Heating/Hot Water related complaint with approximately 2.15 million complaints.\n2. Approximately 28.2% of the complaint comes from the Bronx borough.\n3. The strongest relationship between the number of complaints with the bulding condition is with the number of floors (0.23 by Pearson correlation).\n4. Using a simple polynomial regression, we can predict that the number of complaints at the end of 2020 will reach approximately 79,000 complaints."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}